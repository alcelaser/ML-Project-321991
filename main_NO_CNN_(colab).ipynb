{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alcelaser/ML-Project-321991/blob/main/main_NO_CNN_(colab).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "40X3iBo7IzbY"
      },
      "id": "40X3iBo7IzbY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "48f90a71",
      "metadata": {
        "id": "48f90a71"
      },
      "source": [
        "# Machine Teachers Group Project: PatternMind ; Exploring Semantic Structures in Image Collections\n",
        "\n",
        " A comprehensive analysis of the dataset to uncover visual patterns, clusters, and relationships among image categories. The focus is mianly on understanding and organizing the visual space."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ece6bdc6",
      "metadata": {
        "id": "ece6bdc6"
      },
      "source": [
        "## Section 1: Environment Setup and Data Loading\n",
        "\n",
        "In this section, we will:\n",
        "- Import all necessary libraries for data manipulation, visualization, and machine learning\n",
        "- Load the dataset\n",
        "- Perform initial data inspection to understand the structure, dimensions, and basic characteristics of our dataset\n",
        "\n",
        "The libraries selected cover essential functionalities:\n",
        "- **Data handling**: pandas, numpy for efficient data structures and numerical operations\n",
        "- **Visualization**: matplotlib, seaborn, plotly for exploratory and publication-quality visualizations\n",
        "- **Machine Learning**: scikit-learn for preprocessing, modeling, and evaluation and keras for neural networks, Pillow for image processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "008ff685",
      "metadata": {
        "id": "008ff685"
      },
      "outputs": [],
      "source": [
        "# Import core libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "import warnings\n",
        "import os\n",
        "from pathlib import Path\n",
        "import glob\n",
        "\n",
        "# Image processing libraries\n",
        "from PIL import Image\n",
        "import cv2\n",
        "\n",
        "# Sklearn preprocessing\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder, RobustScaler\n",
        "from sklearn.impute import SimpleImputer, KNNImputer\n",
        "\n",
        "# Sklearn model selection\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, StratifiedKFold\n",
        "\n",
        "# Sklearn metrics\n",
        "from sklearn.metrics import (\n",
        "    classification_report, confusion_matrix, accuracy_score,\n",
        "    precision_score, recall_score, f1_score, roc_auc_score, roc_curve,\n",
        "    silhouette_score, davies_bouldin_score, calinski_harabasz_score\n",
        ")\n",
        "\n",
        "# Models for classification/clustering\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.cluster import KMeans, DBSCAN, AgglomerativeClustering\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "# Deep Learning for feature extraction\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import VGG16, ResNet50, MobileNetV2\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input as vgg16_preprocess\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input as resnet_preprocess\n",
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input as mobilenet_preprocess\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "# Clustering Analysis\n",
        "from sklearn.metrics import normalized_mutual_info_score, adjusted_rand_score, homogeneity_score, completeness_score\n",
        "\n",
        "\n",
        "# Deep Learning for model building and evaluation\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten\n",
        "\n",
        "# Configuration\n",
        "warnings.filterwarnings('ignore')\n",
        "plt.style.use('seaborn-v0_8-darkgrid')\n",
        "sns.set_palette('husl')\n",
        "%matplotlib inline\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "RANDOM_STATE = 67  # we're aware 42 is the industry standard, but we haven't read Hitchhiker's Guide to the Galaxy and 67 is funnier\n",
        "np.random.seed(RANDOM_STATE)\n",
        "\n",
        "print(\"Libraries imported successfully!\")\n",
        "print(f\"NumPy version: {np.__version__}\")\n",
        "print(f\"Pandas version: {pd.__version__}\")\n",
        "print(f\"OpenCV version: {cv2.__version__}\")\n",
        "print(f\"PIL version: {Image.__version__}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f04889d",
      "metadata": {
        "id": "0f04889d"
      },
      "source": [
        "### Load Image Dataset\n",
        "\n",
        "The dataset is organized as a folder-based image collection where:\n",
        "- Each subfolder in represents a distinct visual category\n",
        "- Images within each folder are labeled by their parent folder name\n",
        "- This is a hierarchical structure typical of image classification datasets\n",
        "\n",
        "We will:\n",
        "- Scan the folder to identify all categories\n",
        "- Build a catalog (DataFrame) containing image paths and their corresponding labels (Essentially an image dictionary)\n",
        "- Calculate dataset statistics (number of categories, images per category, total images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "93359d8e",
      "metadata": {
        "id": "93359d8e"
      },
      "outputs": [],
      "source": [
        "# Define the data directory\n",
        "DATA_DIR = Path('/content/drive/MyDrive/DatasetML/data')\n",
        "\n",
        "# Initialize lists to store image paths and labels\n",
        "image_paths = []\n",
        "labels = []\n",
        "\n",
        "# Scan the data directory for category folders\n",
        "print(\"Scanning dataset directory...\")\n",
        "\n",
        "# Get all category folders\n",
        "category_folders = [f for f in DATA_DIR.iterdir() if f.is_dir()]\n",
        "category_folders = sorted(category_folders)\n",
        "\n",
        "print(f\"Found {len(category_folders)} categories\")\n",
        "print(\"\\nScanning images in each category...\")\n",
        "\n",
        "# Iterate through each category folder\n",
        "for category_folder in category_folders:\n",
        "    category_name = category_folder.name\n",
        "\n",
        "    # Find all image files in the category folder\n",
        "    # Support common image formats: jpg, jpeg, png, bmp\n",
        "    image_files = list(category_folder.glob('*.jpg')) + \\\n",
        "                  list(category_folder.glob('*.jpeg')) + \\\n",
        "                  list(category_folder.glob('*.png')) + \\\n",
        "                  list(category_folder.glob('*.bmp'))\n",
        "\n",
        "    # Add to our lists\n",
        "    for img_path in image_files:\n",
        "        image_paths.append(str(img_path))\n",
        "        labels.append(category_name)\n",
        "\n",
        "# Create a DataFrame\n",
        "df = pd.DataFrame({\n",
        "    'image_path': image_paths,\n",
        "    'category': labels\n",
        "})\n",
        "\n",
        "# Display basic information\n",
        "print(\"\\n\" + \".\"*50)\n",
        "print(\"Dataset loaded successfully!\")\n",
        "print(\".\"*50)\n",
        "print(f\"\\nDataset shape: {df.shape}\")\n",
        "print(f\"Total number of images: {df.shape[0]:,}\")\n",
        "print(f\"Number of categories: {df['category'].nunique()}\")\n",
        "\n",
        "print(\"\\n\" + \".\"*50)\n",
        "print(\"Category Distribution:\")\n",
        "print(\".\"*50)\n",
        "category_counts = df['category'].value_counts().sort_index()\n",
        "print(f\"\\nImages per category (first 10):\")\n",
        "display(category_counts.head(10))\n",
        "\n",
        "print(f\"\\nStatistics:\")\n",
        "print(f\"  Mean images per category: {category_counts.mean():.1f}\")\n",
        "print(f\"  Median images per category: {category_counts.median():.1f}\")\n",
        "print(f\"  Min images per category: {category_counts.min()}\")\n",
        "print(f\"  Max images per category: {category_counts.max()}\")\n",
        "\n",
        "print(\"\\n\" + \".\"*50)\n",
        "print(\"First few rows of the dataset:\")\n",
        "display(df.head(10))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b40f6eae",
      "metadata": {
        "id": "b40f6eae"
      },
      "source": [
        "### Dataset Overview and Validation\n",
        "\n",
        "Now we will validate the integrity of our image dataset by:\n",
        "- Checking for any corrupted or unreadable images\n",
        "- Verifying image dimensions and formats\n",
        "- Analyzing the distribution of images across categories\n",
        "- Identifying potential class imbalance issues\n",
        "\n",
        "Below is sample visualization showing example images from random categories to visually confirm the dataset quality and diversity.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "945024a5",
      "metadata": {
        "id": "945024a5"
      },
      "outputs": [],
      "source": [
        "# Sample a few images to check dimensions and formats\n",
        "print(\"Analyzing image properties...\")\n",
        "\n",
        "sample_size = min(100, len(df))\n",
        "sample_indices = np.random.choice(len(df), size=sample_size, replace=False)\n",
        "\n",
        "widths = []\n",
        "heights = []\n",
        "formats = []\n",
        "corrupted_images = []\n",
        "\n",
        "for idx in sample_indices:\n",
        "    img_path = df.iloc[idx]['image_path']\n",
        "    try:\n",
        "        img = Image.open(img_path)\n",
        "        widths.append(img.width)\n",
        "        heights.append(img.height)\n",
        "        formats.append(img.format)\n",
        "        img.close()\n",
        "    except Exception as e:\n",
        "        corrupted_images.append(img_path)\n",
        "        print(f\"Warning: Could not read {img_path}: {e}\")\n",
        "\n",
        "if len(corrupted_images) > 0:\n",
        "    print(f\"\\nFound {len(corrupted_images)} corrupted images\")\n",
        "else:\n",
        "    print(\"\\nAll sampled images are valid\")\n",
        "\n",
        "print(f\"\\nImage Dimensions (from {sample_size} samples):\")\n",
        "print(f\"Width  - Min: {min(widths)}px, Max: {max(widths)}px, Mean: {np.mean(widths):.1f}px\")\n",
        "print(f\"Height - Min: {min(heights)}px, Max: {max(heights)}px, Mean: {np.mean(heights):.1f}px\")\n",
        "print(f\"\\nImage Formats: {set(formats)}\")\n",
        "\n",
        "# Analyze category distribution\n",
        "print(\"\\n\" + \".\"*50)\n",
        "print(\"Category Distribution Analysis:\")\n",
        "print(\".\"*50)\n",
        "\n",
        "category_counts = df['category'].value_counts()\n",
        "print(f\"\\nTop 10 most common categories:\")\n",
        "display(category_counts.head(10))\n",
        "\n",
        "print(f\"\\nTop 10 least common categories:\")\n",
        "display(category_counts.tail(10))\n",
        "\n",
        "# Check for class imbalance\n",
        "imbalance_ratio = category_counts.max() / category_counts.min()\n",
        "print(f\"\\nClass Imbalance Ratio: {imbalance_ratio:.2f}x\")\n",
        "if imbalance_ratio > 3:\n",
        "    print(\"Significant class imbalance detected\")\n",
        "else:\n",
        "    print(\"Relatively balanced dataset\")\n",
        "\n",
        "# Store key information for later use\n",
        "print(\"\\n\" + \".\"*50)\n",
        "print(\"Dataset Summary:\")\n",
        "print(\".\"*50)\n",
        "print(f\"Total Images: {len(df):,}\")\n",
        "print(f\"Total Categories: {df['category'].nunique()}\")\n",
        "print(f\"Average Images per Category: {len(df) / df['category'].nunique():.1f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d83755c7",
      "metadata": {
        "id": "d83755c7"
      },
      "source": [
        "### Visualize Sample Images\n",
        "\n",
        "To better understand our dataset, we'll display a grid of sample images from different categories. This visual inspection helps us:\n",
        "- Verify that images are loading correctly\n",
        "- Understand the visual diversity within and across categories\n",
        "- Identify any obvious data quality issues\n",
        "- Get an intuitive sense of the classification challenge ahead\n",
        "\n",
        "The output will show a grid of randomly selected images with their category labels, giving us a qualitative view of what the model will need to learn to distinguish."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e82cc2a",
      "metadata": {
        "id": "8e82cc2a"
      },
      "outputs": [],
      "source": [
        "# Visualize sample images from different categories\n",
        "n_categories_to_show = 8\n",
        "n_images_per_category = 3\n",
        "\n",
        "# Select random categories\n",
        "random_categories = np.random.choice(df['category'].unique(),\n",
        "                                     size=min(n_categories_to_show, df['category'].nunique()),\n",
        "                                     replace=False)\n",
        "\n",
        "# Create figure\n",
        "fig, axes = plt.subplots(n_categories_to_show, n_images_per_category,\n",
        "                         figsize=(15, 2.5*n_categories_to_show))\n",
        "\n",
        "if n_categories_to_show == 1:\n",
        "    axes = axes.reshape(1, -1)\n",
        "\n",
        "print(\"Displaying sample images from random categories...\")\n",
        "print(\".\"*50)\n",
        "\n",
        "for i, category in enumerate(random_categories):\n",
        "    # Get images from this category\n",
        "    category_df = df[df['category'] == category]\n",
        "\n",
        "    # Sample random images\n",
        "    sampled_images = category_df.sample(n=min(n_images_per_category, len(category_df)))\n",
        "\n",
        "    for j, (idx, row) in enumerate(sampled_images.iterrows()):\n",
        "        img_path = row['image_path']\n",
        "\n",
        "        try:\n",
        "            img = Image.open(img_path)\n",
        "\n",
        "            # Display image\n",
        "            if n_categories_to_show > 1:\n",
        "                ax = axes[i, j]\n",
        "            else:\n",
        "                ax = axes[j]\n",
        "\n",
        "            ax.imshow(img)\n",
        "            ax.axis('off')\n",
        "\n",
        "            if j == 0:  # Add category label to first image in row\n",
        "                ax.set_title(f\"{category}\\n({len(category_df)} images)\",\n",
        "                           fontsize=10, fontweight='bold')\n",
        "\n",
        "            img.close()\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading {img_path}: {e}\")\n",
        "\n",
        "plt.tight_layout()\n",
        "os.makedirs('images', exist_ok=True)\n",
        "plt.savefig('images/sample_images_grid.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "# Additional: Show category name statistics\n",
        "print(\"\\n\" + \".\"*50)\n",
        "print(\"Category Name Analysis:\")\n",
        "print(\".\"*50)\n",
        "print(f\"Shortest category name: '{min(df['category'].unique(), key=len)}' ({len(min(df['category'].unique(), key=len))} chars)\")\n",
        "print(f\"Longest category name: '{max(df['category'].unique(), key=len)}' ({len(max(df['category'].unique(), key=len))} chars)\")\n",
        "print(f\"\\nAll categories ({len(df['category'].unique())} total):\")\n",
        "print(sorted(df['category'].unique()))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "53f06cb6",
      "metadata": {
        "id": "53f06cb6"
      },
      "source": [
        "## Section 2: Exploratory Data Analysis (EDA) and Feature Extraction\n",
        "\n",
        "In this section, we will perform comprehensive exploratory data analysis to understand the visual characteristics of our dataset. Since we're working with images rather than tabular data with pre-extracted features, our EDA will focus on:\n",
        "\n",
        "1. **Visual Feature Extraction**: Extract numerical features from images using pre-trained deep learning models (transfer learning)\n",
        "2. **Feature Distribution Analysis**: Analyze the statistical properties of extracted features\n",
        "3. **Dimensionality Reduction**: Apply PCA and t-SNE to visualize high-dimensional image features in 2D/3D space\n",
        "4. **Category Relationships**: Explore visual similarities and differences between categories\n",
        "5. **Data Visualization**: Create comprehensive visualizations to understand patterns and clusters\n",
        "\n",
        "This analysis will help us determine whether this is best approached as a classification or clustering problem and inform our model selection strategy."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b6f54e78",
      "metadata": {
        "id": "b6f54e78"
      },
      "source": [
        "### Category Distribution Visualization\n",
        "\n",
        "We viusalise the distribution of the images such that we can:\n",
        "- Identify class imbalance issues that may require stratified sampling or data augmentation\n",
        "- Understand which categories are well-represented vs. under-represented\n",
        "- Make informed decisions about train/validation/test split strategies\n",
        "\n",
        "Our visualisation includes:\n",
        "- Bar chart showing top and bottom categories by image count\n",
        "- Histogram of images per category distribution\n",
        "- Interactive plotly visualization for detailed exploration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cdf683e8",
      "metadata": {
        "id": "cdf683e8"
      },
      "outputs": [],
      "source": [
        "# Analyze category distribution in detail\n",
        "print(\"Category Distribution Analysis\")\n",
        "\n",
        "category_counts = df['category'].value_counts()\n",
        "\n",
        "# Create figure with multiple subplots\n",
        "fig = plt.figure(figsize=(20, 12))\n",
        "gs = fig.add_gridspec(3, 2, hspace=0.3, wspace=0.3)\n",
        "\n",
        "# 1. Top 20 categories bar chart\n",
        "ax1 = fig.add_subplot(gs[0, 0])\n",
        "top_20 = category_counts.head(20)\n",
        "ax1.barh(range(len(top_20)), top_20.values, color='steelblue')\n",
        "ax1.set_yticks(range(len(top_20)))\n",
        "ax1.set_yticklabels(top_20.index, fontsize=9)\n",
        "ax1.set_xlabel('Number of Images', fontsize=11)\n",
        "ax1.set_title('Top 20 Categories by Image Count', fontsize=13, fontweight='bold')\n",
        "ax1.invert_yaxis()\n",
        "for i, v in enumerate(top_20.values):\n",
        "    ax1.text(v + 5, i, str(v), va='center', fontsize=8)\n",
        "\n",
        "# 2. Bottom 20 categories bar chart\n",
        "ax2 = fig.add_subplot(gs[0, 1])\n",
        "bottom_20 = category_counts.tail(20).sort_values(ascending=False)\n",
        "ax2.barh(range(len(bottom_20)), bottom_20.values, color='coral')\n",
        "ax2.set_yticks(range(len(bottom_20)))\n",
        "ax2.set_yticklabels(bottom_20.index, fontsize=9)\n",
        "ax2.set_xlabel('Number of Images', fontsize=11)\n",
        "ax2.set_title('Bottom 20 Categories by Image Count', fontsize=13, fontweight='bold')\n",
        "ax2.invert_yaxis()\n",
        "for i, v in enumerate(bottom_20.values):\n",
        "    ax2.text(v + 1, i, str(v), va='center', fontsize=8)\n",
        "\n",
        "# 3. Histogram of category sizes\n",
        "ax3 = fig.add_subplot(gs[1, :])\n",
        "ax3.hist(category_counts.values, bins=30, color='mediumseagreen', edgecolor='black', alpha=0.7)\n",
        "ax3.axvline(category_counts.mean(), color='red', linestyle='--', linewidth=2, label=f'Mean: {category_counts.mean():.1f}')\n",
        "ax3.axvline(category_counts.median(), color='blue', linestyle='--', linewidth=2, label=f'Median: {category_counts.median():.1f}')\n",
        "ax3.set_xlabel('Number of Images per Category', fontsize=11)\n",
        "ax3.set_ylabel('Frequency (Number of Categories)', fontsize=11)\n",
        "ax3.set_title('Distribution of Images Across Categories', fontsize=13, fontweight='bold')\n",
        "ax3.legend(fontsize=10)\n",
        "ax3.grid(axis='y', alpha=0.3)\n",
        "\n",
        "# 4. Box plot\n",
        "ax4 = fig.add_subplot(gs[2, 0])\n",
        "ax4.boxplot(category_counts.values, vert=True, patch_artist=True,\n",
        "            boxprops=dict(facecolor='lightblue', alpha=0.7),\n",
        "            medianprops=dict(color='red', linewidth=2))\n",
        "ax4.set_ylabel('Number of Images', fontsize=11)\n",
        "ax4.set_title('Box Plot of Category Sizes', fontsize=13, fontweight='bold')\n",
        "ax4.grid(axis='y', alpha=0.3)\n",
        "\n",
        "# 5. Statistics summary text\n",
        "ax5 = fig.add_subplot(gs[2, 1])\n",
        "ax5.axis('off')\n",
        "stats_text = f\"\"\"\n",
        "CATEGORY DISTRIBUTION STATISTICS\n",
        "\n",
        "Total Categories: {len(category_counts)}\n",
        "Total Images: {category_counts.sum():,}\n",
        "\n",
        "Images per Category:\n",
        "  • Mean:     {category_counts.mean():.2f}\n",
        "  • Median:   {category_counts.median():.2f}\n",
        "  • Std Dev:  {category_counts.std():.2f}\n",
        "  • Min:      {category_counts.min()}\n",
        "  • Max:      {category_counts.max()}\n",
        "  • Q1:       {category_counts.quantile(0.25):.2f}\n",
        "  • Q3:       {category_counts.quantile(0.75):.2f}\n",
        "\n",
        "Class Imbalance Ratio: {category_counts.max() / category_counts.min():.2f}x\n",
        "\n",
        "Most Common: {category_counts.index[0]} ({category_counts.values[0]} images)\n",
        "Least Common: {category_counts.index[-1]} ({category_counts.values[-1]} images)\n",
        "\"\"\"\n",
        "ax5.text(0.1, 0.5, stats_text, fontsize=11, family='monospace',\n",
        "         verticalalignment='center', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
        "\n",
        "plt.savefig('images/category_distribution_analysis.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ddd4e8ba",
      "metadata": {
        "id": "ddd4e8ba"
      },
      "source": [
        "### Feature Extraction Using Pre-trained Model\n",
        "\n",
        "Since our data consists of images without pre-extracted features, we need to convert images into numerical feature vectors. We'll use transfer learning with a pre-trained deep neural network to extract high-quality visual features.\n",
        "\n",
        "We do so because re-trained models (like VGG16, ResNet50) have learned rich visual representations from millions of images, these features capture edges, textures, shapes, and complex patterns. This is much more effective than hand-crafted features (HOG, SIFT, etc.) for diverse image collections, and is more computationally effcient as we extract features once and reuse them for the rest of the model.\n",
        "\n",
        "**Process:**\n",
        "1. Load a pre-trained model\n",
        "2. Remove the classification head to get feature extractor\n",
        "3. Process images in batches to extract feature vectors\n",
        "4. Each image will be represented as a fixed-length numerical vector (typically 1280 dimensions for MobileNetV2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d9bc249",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3d9bc249",
        "outputId": "e31bd5e9-68c8-477b-d217-9eda1fda6103"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing Feature Extraction\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n",
            "MobileNetV2 loaded successfully\n",
            "Feature vector dimension: 1280\n",
            "\n",
            "Extracting features from all images...\n",
            "This may take several minutes...\n",
            "......................................................................\n",
            "Progress: 1.3% (10/799 batches) - 320 images processed\n",
            "Progress: 2.5% (20/799 batches) - 640 images processed\n",
            "Progress: 3.8% (30/799 batches) - 960 images processed\n",
            "Progress: 5.0% (40/799 batches) - 1280 images processed\n",
            "Progress: 6.3% (50/799 batches) - 1600 images processed\n"
          ]
        }
      ],
      "source": [
        "# Feature Extraction using MobileNetV2\n",
        "print(\"Initializing Feature Extraction\")\n",
        "\n",
        "# Load pre-trained MobileNetV2 model without top classification layer, this is pur feature extractor\n",
        "base_model = tf.keras.applications.MobileNetV2(\n",
        "    input_shape=(224, 224, 3),\n",
        "    include_top=False,  # Remove classification head\n",
        "    weights='imagenet',\n",
        "    pooling='avg'  # Global average pooling to get fixed-size feature vector\n",
        ")\n",
        "\n",
        "print(f\"MobileNetV2 loaded successfully\")\n",
        "print(f\"Feature vector dimension: {base_model.output_shape[1]}\")\n",
        "\n",
        "# Function to preprocess and extract features from an image\n",
        "def extract_features(img_path, target_size=(224, 224)):\n",
        "    \"\"\"Extract features from a single image using MobileNetV2\"\"\"\n",
        "    try:\n",
        "        # Load and preprocess image\n",
        "        img = tf.keras.preprocessing.image.load_img(img_path, target_size=target_size)\n",
        "        img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
        "        img_array = np.expand_dims(img_array, axis=0)\n",
        "        img_array = tf.keras.applications.mobilenet_v2.preprocess_input(img_array)\n",
        "\n",
        "        # Extract features\n",
        "        features = base_model.predict(img_array, verbose=0)\n",
        "        return features.flatten()\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {img_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "# Extract features for all images (with progress tracking)\n",
        "print(\"\\nExtracting features from all images...\")\n",
        "print(\"This may take several minutes...\")\n",
        "print(\".\"*70)\n",
        "\n",
        "features_list = []\n",
        "valid_indices = []\n",
        "failed_images = []\n",
        "\n",
        "# Process images in batches for efficiency\n",
        "batch_size = 32\n",
        "n_batches = int(np.ceil(len(df) / batch_size))\n",
        "\n",
        "for batch_idx in range(n_batches):\n",
        "    start_idx = batch_idx * batch_size\n",
        "    end_idx = min((batch_idx + 1) * batch_size, len(df))\n",
        "\n",
        "    batch_images = []\n",
        "    batch_indices = []\n",
        "\n",
        "    # Load batch of images\n",
        "    for idx in range(start_idx, end_idx):\n",
        "        img_path = df.iloc[idx]['image_path']\n",
        "        try:\n",
        "            img = tf.keras.preprocessing.image.load_img(img_path, target_size=(224, 224))\n",
        "            img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
        "            batch_images.append(img_array)\n",
        "            batch_indices.append(idx)\n",
        "        except Exception as e:\n",
        "            failed_images.append(img_path)\n",
        "            continue\n",
        "\n",
        "    if len(batch_images) > 0:\n",
        "        # Preprocess batch\n",
        "        batch_images = np.array(batch_images)\n",
        "        batch_images = tf.keras.applications.mobilenet_v2.preprocess_input(batch_images)\n",
        "\n",
        "        # Extract features for batch\n",
        "        batch_features = base_model.predict(batch_images, verbose=0)\n",
        "\n",
        "        # Store features and indices\n",
        "        for i, features in enumerate(batch_features):\n",
        "            features_list.append(features)\n",
        "            valid_indices.append(batch_indices[i])\n",
        "\n",
        "    # Progress update\n",
        "    if (batch_idx + 1) % 10 == 0 or (batch_idx + 1) == n_batches:\n",
        "        progress = ((batch_idx + 1) / n_batches) * 100\n",
        "        print(f\"Progress: {progress:.1f}% ({batch_idx + 1}/{n_batches} batches) - \"\n",
        "              f\"{len(features_list)} images processed\")\n",
        "\n",
        "# Convert to numpy array\n",
        "features_array = np.array(features_list)\n",
        "\n",
        "# Create cleaned dataframe with only successfully processed images\n",
        "df_features = df.iloc[valid_indices].copy().reset_index(drop=True)\n",
        "\n",
        "\n",
        "print(\"\\n Feature Extraction Complete!\")\n",
        "\n",
        "print(f\"Successfully extracted features from: {len(features_list):,} images\")\n",
        "print(f\"Failed to process: {len(failed_images)} images\")\n",
        "print(f\"Feature matrix shape: {features_array.shape}\")\n",
        "print(f\"{features_array.shape[0]:,} samples\")\n",
        "print(f\"{features_array.shape[1]} features per image\")\n",
        "print(f\"\\nMemory usage: {features_array.nbytes / (1024**2):.2f} MB\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4e61a117",
      "metadata": {
        "id": "4e61a117"
      },
      "source": [
        "### Feature Distribution Analysis\n",
        "\n",
        "With numerical feature vectors we can analyse their statistical features:\n",
        "- Distribution of feature values (mean, variance, range)\n",
        "- Correlation between features\n",
        "- Identify redundant or highly correlated features\n",
        "- Check for any anomalies or outliers in the feature space\n",
        "\n",
        "We do this so that we can tell:\n",
        "- Whether features need scaling/normalization\n",
        "- If dimensionality reduction would be beneficial\n",
        "- The complexity of the feature space we're working with"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fefe8ea4",
      "metadata": {
        "id": "fefe8ea4"
      },
      "outputs": [],
      "source": [
        "# Analyze feature distributions\n",
        "print(\"Feature Distribution Analysis\")\n",
        "\n",
        "# Basic statistics\n",
        "feature_means = features_array.mean(axis=0)\n",
        "feature_stds = features_array.std(axis=0)\n",
        "feature_mins = features_array.min(axis=0)\n",
        "feature_maxs = features_array.max(axis=0)\n",
        "\n",
        "print(f\"\\nFeature Statistics Summary:\")\n",
        "print(f\"  Mean of means: {feature_means.mean():.4f}\")\n",
        "print(f\"  Mean of stds:  {feature_stds.mean():.4f}\")\n",
        "print(f\"  Global min:    {feature_mins.min():.4f}\")\n",
        "print(f\"  Global max:    {feature_maxs.max():.4f}\")\n",
        "\n",
        "# Create comprehensive visualization\n",
        "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
        "\n",
        "# 1. Distribution of feature means\n",
        "axes[0, 0].hist(feature_means, bins=50, color='steelblue', edgecolor='black', alpha=0.7)\n",
        "axes[0, 0].set_xlabel('Feature Mean Value', fontsize=10)\n",
        "axes[0, 0].set_ylabel('Frequency', fontsize=10)\n",
        "axes[0, 0].set_title('Distribution of Feature Means', fontsize=11, fontweight='bold')\n",
        "axes[0, 0].grid(alpha=0.3)\n",
        "\n",
        "# 2. Distribution of feature standard deviations\n",
        "axes[0, 1].hist(feature_stds, bins=50, color='coral', edgecolor='black', alpha=0.7)\n",
        "axes[0, 1].set_xlabel('Feature Std Dev', fontsize=10)\n",
        "axes[0, 1].set_ylabel('Frequency', fontsize=10)\n",
        "axes[0, 1].set_title('Distribution of Feature Std Deviations', fontsize=11, fontweight='bold')\n",
        "axes[0, 1].grid(alpha=0.3)\n",
        "\n",
        "# 3. Distribution of feature ranges\n",
        "feature_ranges = feature_maxs - feature_mins\n",
        "axes[0, 2].hist(feature_ranges, bins=50, color='mediumseagreen', edgecolor='black', alpha=0.7)\n",
        "axes[0, 2].set_xlabel('Feature Range (Max - Min)', fontsize=10)\n",
        "axes[0, 2].set_ylabel('Frequency', fontsize=10)\n",
        "axes[0, 2].set_title('Distribution of Feature Ranges', fontsize=11, fontweight='bold')\n",
        "axes[0, 2].grid(alpha=0.3)\n",
        "\n",
        "# 4. Sample feature values across images (first 100 features)\n",
        "n_features_to_plot = min(100, features_array.shape[1])\n",
        "im = axes[1, 0].imshow(features_array[:200, :n_features_to_plot].T,\n",
        "                       aspect='auto', cmap='viridis', interpolation='nearest')\n",
        "axes[1, 0].set_xlabel('Image Index', fontsize=10)\n",
        "axes[1, 0].set_ylabel(f'Feature Index (first {n_features_to_plot})', fontsize=10)\n",
        "axes[1, 0].set_title('Feature Value Heatmap (Sample)', fontsize=11, fontweight='bold')\n",
        "plt.colorbar(im, ax=axes[1, 0])\n",
        "\n",
        "# 5. Feature correlation sample (random subset to avoid memory issues)\n",
        "n_features_corr = min(50, features_array.shape[1])\n",
        "random_feature_indices = np.random.choice(features_array.shape[1], n_features_corr, replace=False)\n",
        "feature_subset = features_array[:, random_feature_indices]\n",
        "correlation_matrix = np.corrcoef(feature_subset.T)\n",
        "\n",
        "im2 = axes[1, 1].imshow(correlation_matrix, cmap='coolwarm', vmin=-1, vmax=1, aspect='auto')\n",
        "axes[1, 1].set_xlabel('Feature Index', fontsize=10)\n",
        "axes[1, 1].set_ylabel('Feature Index', fontsize=10)\n",
        "axes[1, 1].set_title(f'Feature Correlation Matrix ({n_features_corr} random features)',\n",
        "                     fontsize=11, fontweight='bold')\n",
        "plt.colorbar(im2, ax=axes[1, 1])\n",
        "\n",
        "# 6. Distribution of a few sample features\n",
        "sample_features_idx = np.random.choice(features_array.shape[1], 5, replace=False)\n",
        "for i, feat_idx in enumerate(sample_features_idx):\n",
        "    axes[1, 2].hist(features_array[:, feat_idx], bins=30, alpha=0.5,\n",
        "                    label=f'Feature {feat_idx}', edgecolor='black')\n",
        "axes[1, 2].set_xlabel('Feature Value', fontsize=10)\n",
        "axes[1, 2].set_ylabel('Frequency', fontsize=10)\n",
        "axes[1, 2].set_title('Sample Feature Distributions', fontsize=11, fontweight='bold')\n",
        "axes[1, 2].legend(fontsize=8)\n",
        "axes[1, 2].grid(alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('images/feature_distribution_analysis.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "# Check for zero-variance features\n",
        "zero_var_features = np.where(feature_stds < 1e-10)[0]\n",
        "print(f\"\\nZero-variance features: {len(zero_var_features)}\")\n",
        "if len(zero_var_features) > 0:\n",
        "    print(f\"  These features have no variation and could be removed\")\n",
        "\n",
        "# Check sparsity\n",
        "sparsity = (features_array == 0).sum() / features_array.size * 100\n",
        "print(f\"\\nFeature sparsity: {sparsity:.2f}% (percentage of zero values)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "50d2cb11",
      "metadata": {
        "id": "50d2cb11"
      },
      "source": [
        "### Dimensionality Reduction and Visualization\n",
        "\n",
        "Our features are high-dimensional (1280 dimensions from MobileNetV2), making them impossible to visualize directly. We'll apply dimensionality reduction techniques learned in statistics to project the data into 2D and 3D spaces:\n",
        "\n",
        "**Principal Component Analysis with 3 Principal Components (PCA 3D):**\n",
        "- Linear dimensionality reduction\n",
        "- Preserves global structure and maximum variance\n",
        "- Fast and deterministic\n",
        "\n",
        "**t-SNE (t-Distributed Stochastic Neighbor Embedding):**\n",
        "- Non-linear dimensionality reduction\n",
        "- Preserves local structure and reveals clusters\n",
        "- Better for visualization of complex patterns\n",
        "- Shows how similar images group together\n",
        "\n",
        "We'll use these visualisations to understand whether categories form distinct clusters (suggesting classification is appropriate) and identify overlapping categories (areas of ambiguity) or discover natural groupings in the data (for clustering). With the visualisation we can also assess the separability of different visual concepts\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d34323e5",
      "metadata": {
        "id": "d34323e5"
      },
      "outputs": [],
      "source": [
        "# Dimensionality Reduction for Visualization\n",
        "print(\"Applying Dimensionality Reduction Techniques\")\n",
        "\n",
        "# For visualization, we'll use a subset if dataset is very large\n",
        "max_samples_for_viz = 5000\n",
        "if len(features_array) > max_samples_for_viz:\n",
        "    print(f\"\\nDataset has {len(features_array)} samples - using stratified sample of {max_samples_for_viz} for visualization\")\n",
        "    # Stratified sampling to maintain category proportions\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    _, X_viz, _, y_viz = train_test_split(\n",
        "        features_array,\n",
        "        df_features['category'],\n",
        "        train_size=(len(features_array) - max_samples_for_viz),\n",
        "        stratify=df_features['category'],\n",
        "        random_state=RANDOM_STATE\n",
        "    )\n",
        "else:\n",
        "    X_viz = features_array\n",
        "    y_viz = df_features['category']\n",
        "\n",
        "print(f\"Visualization sample size: {len(X_viz)} images\")\n",
        "\n",
        "# 1. PCA - Principal Component Analysis\n",
        "print(\"\\n\" + \".\"*70)\n",
        "print(\"1. Applying PCA...\")\n",
        "pca_2d = PCA(n_components=2, random_state=RANDOM_STATE)\n",
        "pca_3d = PCA(n_components=3, random_state=RANDOM_STATE)\n",
        "\n",
        "X_pca_2d = pca_2d.fit_transform(X_viz)\n",
        "X_pca_3d = pca_3d.fit_transform(X_viz)\n",
        "\n",
        "print(f\"PCA 2D: Explained variance: {pca_2d.explained_variance_ratio_.sum()*100:.2f}%\")\n",
        "print(f\"PCA 3D: Explained variance: {pca_3d.explained_variance_ratio_.sum()*100:.2f}%\")\n",
        "\n",
        "# 2. t-SNE - T-distributed Stochastic Neighbor Embedding\n",
        "print(\"\\n\" + \".\"*70)\n",
        "print(\"2. Applying t-SNE (this may take a few minutes)...\")\n",
        "\n",
        "# Use PCA preprocessing for t-SNE (recommended practice)\n",
        "pca_50 = PCA(n_components=50, random_state=RANDOM_STATE)\n",
        "X_pca_50 = pca_50.fit_transform(X_viz)\n",
        "\n",
        "tsne_2d = TSNE(n_components=2, random_state=RANDOM_STATE, perplexity=30, max_iter=1000)\n",
        "X_tsne_2d = tsne_2d.fit_transform(X_pca_50)\n",
        "\n",
        "print(f\"t-SNE 2D completed\")\n",
        "\n",
        "# Create visualizations\n",
        "print(\"\\n Creating visualizations...\")\n",
        "\n",
        "# Encode categories as numbers for coloring\n",
        "le = LabelEncoder()\n",
        "y_viz_encoded = le.fit_transform(y_viz)\n",
        "\n",
        "# Create a colormap\n",
        "n_categories = len(np.unique(y_viz_encoded))\n",
        "colors = plt.cm.tab20(np.linspace(0, 1, min(n_categories, 20)))\n",
        "\n",
        "# Create figure with subplots\n",
        "fig = plt.figure(figsize=(20, 10))\n",
        "\n",
        "# 1. PCA 2D\n",
        "ax1 = fig.add_subplot(2, 2, 1)\n",
        "scatter1 = ax1.scatter(X_pca_2d[:, 0], X_pca_2d[:, 1],\n",
        "                       c=y_viz_encoded, cmap='tab20',\n",
        "                       s=20, alpha=0.6, edgecolors='none')\n",
        "ax1.set_xlabel(f'PC1 ({pca_2d.explained_variance_ratio_[0]*100:.1f}% variance)', fontsize=11)\n",
        "ax1.set_ylabel(f'PC2 ({pca_2d.explained_variance_ratio_[1]*100:.1f}% variance)', fontsize=11)\n",
        "ax1.set_title('PCA - 2D Projection', fontsize=13, fontweight='bold')\n",
        "ax1.grid(alpha=0.3)\n",
        "\n",
        "# 2. PCA 3D\n",
        "ax2 = fig.add_subplot(2, 2, 2, projection='3d')\n",
        "scatter2 = ax2.scatter(X_pca_3d[:, 0], X_pca_3d[:, 1], X_pca_3d[:, 2],\n",
        "                       c=y_viz_encoded, cmap='tab20',\n",
        "                       s=20, alpha=0.6, edgecolors='none')\n",
        "ax2.set_xlabel(f'PC1 ({pca_3d.explained_variance_ratio_[0]*100:.1f}%)', fontsize=10)\n",
        "ax2.set_ylabel(f'PC2 ({pca_3d.explained_variance_ratio_[1]*100:.1f}%)', fontsize=10)\n",
        "ax2.set_zlabel(f'PC3 ({pca_3d.explained_variance_ratio_[2]*100:.1f}%)', fontsize=10)\n",
        "ax2.set_title('PCA - 3D Projection', fontsize=13, fontweight='bold')\n",
        "\n",
        "# 3. t-SNE 2D\n",
        "ax3 = fig.add_subplot(2, 2, 3)\n",
        "scatter3 = ax3.scatter(X_tsne_2d[:, 0], X_tsne_2d[:, 1],\n",
        "                       c=y_viz_encoded, cmap='tab20',\n",
        "                       s=20, alpha=0.6, edgecolors='none')\n",
        "ax3.set_xlabel('t-SNE Dimension 1', fontsize=11)\n",
        "ax3.set_ylabel('t-SNE Dimension 2', fontsize=11)\n",
        "ax3.set_title('t-SNE - 2D Projection', fontsize=13, fontweight='bold')\n",
        "ax3.grid(alpha=0.3)\n",
        "\n",
        "# 4. Explained variance plot for PCA\n",
        "ax4 = fig.add_subplot(2, 2, 4)\n",
        "pca_full = PCA(random_state=RANDOM_STATE)\n",
        "pca_full.fit(X_viz)\n",
        "cumsum_variance = np.cumsum(pca_full.explained_variance_ratio_)\n",
        "n_components_90 = np.argmax(cumsum_variance >= 0.90) + 1\n",
        "n_components_95 = np.argmax(cumsum_variance >= 0.95) + 1\n",
        "\n",
        "ax4.plot(range(1, min(51, len(cumsum_variance)+1)),\n",
        "         cumsum_variance[:50],\n",
        "         'b-', linewidth=2, label='Cumulative Variance')\n",
        "ax4.axhline(y=0.90, color='r', linestyle='--', label='90% variance')\n",
        "ax4.axhline(y=0.95, color='g', linestyle='--', label='95% variance')\n",
        "ax4.axvline(x=n_components_90, color='r', linestyle=':', alpha=0.5)\n",
        "ax4.axvline(x=n_components_95, color='g', linestyle=':', alpha=0.5)\n",
        "ax4.set_xlabel('Number of Components', fontsize=11)\n",
        "ax4.set_ylabel('Cumulative Explained Variance', fontsize=11)\n",
        "ax4.set_title(f'PCA Variance Explained (90%={n_components_90}, 95%={n_components_95} components)',\n",
        "              fontsize=11, fontweight='bold')\n",
        "ax4.grid(alpha=0.3)\n",
        "ax4.legend(fontsize=9)\n",
        "ax4.set_xlim(0, 50)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('images/dimensionality_reduction_visualization.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n\" + \".\"*70)\n",
        "print(\"Dimensionality Reduction Summary:\")\n",
        "print(\".\"*70)\n",
        "print(f\"PCA Analysis:\")\n",
        "print(f\"Components for 90% variance: {n_components_90}\")\n",
        "print(f\"Components for 95% variance: {n_components_95}\")\n",
        "print(f\"First 2 components capture: {pca_2d.explained_variance_ratio_.sum()*100:.2f}% of variance\")\n",
        "print(f\"First 3 components capture: {pca_3d.explained_variance_ratio_.sum()*100:.2f}% of variance\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce805edd",
      "metadata": {
        "id": "ce805edd"
      },
      "source": [
        "**This is a CLASSIFICATION problem**, but we will:\n",
        "1. Use classification models to predict categories\n",
        "2. Also apply clustering to discover if the visual features align with semantic categories\n",
        "3. Compare supervised and unsupervised approaches to understand data organization\n",
        "\n",
        "The visualizations from t-SNE/PCA will help us assess how well-separated the categories are in visual feature space, if there are any natural clusters that arise and which categories are most likely to be confused (i.e the most cat-looking dog and the most dog-looking cat)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "73a15c26",
      "metadata": {
        "id": "73a15c26"
      },
      "source": [
        "## Section 3: Data Preprocessing and Dataset Splitting\n",
        "\n",
        "We prepare the data for model training in four steps:\n",
        "\n",
        "1. **Feature Scaling**: Normalize features to ensure all features contribute equally\n",
        "2. **Encode Labels**: Convert categorical labels to numerical format\n",
        "3. **Train/Validation/Test Split**: Create stratified splits to maintain class distribution\n",
        "4. **Handle Class Imbalance**: Check if additional techniques are needed\n",
        "\n",
        "The goal is to create a clean properly formatted dataset ready for our neural net and such that we can apply traditional clustering algorithms to it."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "657fa20b",
      "metadata": {
        "id": "657fa20b"
      },
      "source": [
        "### Feature Scaling and Label Encoding\n",
        "\n",
        "We standardize features using StandardScaler (zero mean, unit variance) and encode category labels to integers for model compatibility."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "29f7d628",
      "metadata": {
        "id": "29f7d628"
      },
      "outputs": [],
      "source": [
        "# Feature Scaling and Label Encoding\n",
        "print(\"Preprocessing Features and Labels\")\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(df_features['category'])\n",
        "\n",
        "print(f\"\\nLabel Encoding:\")\n",
        "print(f\"  Number of classes: {len(label_encoder.classes_)}\")\n",
        "print(f\"  Classes: {label_encoder.classes_[:10]}...\" if len(label_encoder.classes_) > 10 else f\"  Classes: {label_encoder.classes_}\")\n",
        "\n",
        "# Feature scaling\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(features_array)\n",
        "\n",
        "print(f\"\\nFeature Scaling:\")\n",
        "print(f\"  Original features - Mean: {features_array.mean():.4f}, Std: {features_array.std():.4f}\")\n",
        "print(f\"  Scaled features   - Mean: {X_scaled.mean():.4f}, Std: {X_scaled.std():.4f}\")\n",
        "print(f\"\\nPreprocessing complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "99494867",
      "metadata": {
        "id": "99494867"
      },
      "source": [
        "### Train/Validation/Test Split\n",
        "\n",
        "We use stratified splitting to maintain class proportions:\n",
        "- **Training set (70%)**: For model training\n",
        "- **Validation set (15%)**: For hyperparameter tuning\n",
        "- **Test set (15%)**: For final evaluation (only used once at the end)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b54046e",
      "metadata": {
        "id": "0b54046e"
      },
      "outputs": [],
      "source": [
        "# Create stratified train/validation/test splits\n",
        "print(\"Creating Train/Validation/Test Splits\")\n",
        "\n",
        "# First split: separate test set (15%)\n",
        "X_temp, X_test, y_temp, y_test = train_test_split(\n",
        "    X_scaled, y_encoded,\n",
        "    test_size=0.15,\n",
        "    stratify=y_encoded,\n",
        "    random_state=RANDOM_STATE\n",
        ")\n",
        "\n",
        "# Second split: separate validation set from remaining data (15% of total = ~17.6% of temp)\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_temp, y_temp,\n",
        "    test_size=0.176,  # This gives us 15% of the original data\n",
        "    stratify=y_temp,\n",
        "    random_state=RANDOM_STATE\n",
        ")\n",
        "\n",
        "print(f\"\\nDataset Splits:\")\n",
        "print(f\"  Training set:   {X_train.shape[0]:,} samples ({X_train.shape[0]/len(X_scaled)*100:.1f}%)\")\n",
        "print(f\"  Validation set: {X_val.shape[0]:,} samples ({X_val.shape[0]/len(X_scaled)*100:.1f}%)\")\n",
        "print(f\"  Test set:       {X_test.shape[0]:,} samples ({X_test.shape[0]/len(X_scaled)*100:.1f}%)\")\n",
        "print(f\"  Total:          {len(X_scaled):,} samples\")\n",
        "\n",
        "# Verify class distribution\n",
        "print(f\"\\nClass Distribution Verification:\")\n",
        "print(f\"  Original:   {np.bincount(y_encoded).min()} to {np.bincount(y_encoded).max()} samples per class\")\n",
        "print(f\"  Training:   {np.bincount(y_train).min()} to {np.bincount(y_train).max()} samples per class\")\n",
        "print(f\"  Validation: {np.bincount(y_val).min()} to {np.bincount(y_val).max()} samples per class\")\n",
        "print(f\"  Test:       {np.bincount(y_test).min()} to {np.bincount(y_test).max()} samples per class\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "afa4a0ab",
      "metadata": {
        "id": "afa4a0ab"
      },
      "source": [
        "## Section 4: Clustering Analysis\n",
        "\n",
        "We apply K-Means and Hierarchical Clustering to the feature reduced representations of the data done before to discover natural groupings in visual features and compare with true categories."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33cfee39",
      "metadata": {
        "id": "33cfee39"
      },
      "outputs": [],
      "source": [
        "# Number of clusters = number of categories\n",
        "n_clusters = len(label_encoder.classes_)\n",
        "print(f\"Number of clusters: {n_clusters}\\n\")\n",
        "\n",
        "# K-Means Clustering\n",
        "kmeans = KMeans(n_clusters=n_clusters, random_state=RANDOM_STATE, n_init=10)\n",
        "kmeans_labels = kmeans.fit_predict(X_scaled)\n",
        "\n",
        "km_silhouette = silhouette_score(X_scaled, kmeans_labels)\n",
        "km_nmi = normalized_mutual_info_score(y_encoded, kmeans_labels)\n",
        "km_ari = adjusted_rand_score(y_encoded, kmeans_labels)\n",
        "\n",
        "# Hierarchical Clustering\n",
        "hier = AgglomerativeClustering(n_clusters=n_clusters, linkage='ward')\n",
        "hier_labels = hier.fit_predict(X_scaled)\n",
        "\n",
        "hier_silhouette = silhouette_score(X_scaled, hier_labels)\n",
        "hier_nmi = normalized_mutual_info_score(y_encoded, hier_labels)\n",
        "hier_ari = adjusted_rand_score(y_encoded, hier_labels)\n",
        "\n",
        "\n",
        "# Visualization\n",
        "\n",
        "# Compute PCA and t-SNE for full dataset\n",
        "pca_2d_full = PCA(n_components=2, random_state=RANDOM_STATE)\n",
        "X_pca_2d_full = pca_2d_full.fit_transform(X_scaled)\n",
        "\n",
        "pca_50_full = PCA(n_components=50, random_state=RANDOM_STATE)\n",
        "X_pca_50_full = pca_50_full.fit_transform(X_scaled)\n",
        "tsne_2d_full = TSNE(n_components=2, random_state=RANDOM_STATE, perplexity=30, max_iter=1000)\n",
        "X_tsne_2d_full = tsne_2d_full.fit_transform(X_pca_50_full)\n",
        "\n",
        "# Create visualization\n",
        "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
        "\n",
        "# K-Means - PCA\n",
        "axes[0, 0].scatter(X_pca_2d_full[:, 0], X_pca_2d_full[:, 1], c=kmeans_labels, cmap='tab20', s=10, alpha=0.6)\n",
        "axes[0, 0].set_title('K-Means - PCA', fontsize=12, fontweight='bold')\n",
        "axes[0, 0].set_xlabel('PC1')\n",
        "axes[0, 0].set_ylabel('PC2')\n",
        "\n",
        "# K-Means - t-SNE\n",
        "axes[0, 1].scatter(X_tsne_2d_full[:, 0], X_tsne_2d_full[:, 1], c=kmeans_labels, cmap='tab20', s=10, alpha=0.6)\n",
        "axes[0, 1].set_title('K-Means - t-SNE', fontsize=12, fontweight='bold')\n",
        "axes[0, 1].set_xlabel('t-SNE 1')\n",
        "axes[0, 1].set_ylabel('t-SNE 2')\n",
        "\n",
        "# True categories - t-SNE\n",
        "axes[0, 2].scatter(X_tsne_2d_full[:, 0], X_tsne_2d_full[:, 1], c=y_encoded, cmap='tab20', s=10, alpha=0.6)\n",
        "axes[0, 2].set_title('True Categories - t-SNE', fontsize=12, fontweight='bold')\n",
        "axes[0, 2].set_xlabel('t-SNE 1')\n",
        "axes[0, 2].set_ylabel('t-SNE 2')\n",
        "\n",
        "# Hierarchical - PCA\n",
        "axes[1, 0].scatter(X_pca_2d_full[:, 0], X_pca_2d_full[:, 1], c=hier_labels, cmap='tab20', s=10, alpha=0.6)\n",
        "axes[1, 0].set_title('Hierarchical - PCA', fontsize=12, fontweight='bold')\n",
        "axes[1, 0].set_xlabel('PC1')\n",
        "axes[1, 0].set_ylabel('PC2')\n",
        "\n",
        "# Hierarchical - t-SNE\n",
        "axes[1, 1].scatter(X_tsne_2d_full[:, 0], X_tsne_2d_full[:, 1], c=hier_labels, cmap='tab20', s=10, alpha=0.6)\n",
        "axes[1, 1].set_title('Hierarchical - t-SNE', fontsize=12, fontweight='bold')\n",
        "axes[1, 1].set_xlabel('t-SNE 1')\n",
        "axes[1, 1].set_ylabel('t-SNE 2')\n",
        "\n",
        "# Metrics comparison\n",
        "axes[1, 2].axis('off')\n",
        "metrics_text = f\"\"\"\n",
        "CLUSTERING METRICS\n",
        "\n",
        "K-Means:\n",
        "  Silhouette: {km_silhouette:.4f}\n",
        "  NMI:        {km_nmi:.4f}\n",
        "  ARI:        {km_ari:.4f}\n",
        "\n",
        "Hierarchical:\n",
        "  Silhouette: {hier_silhouette:.4f}\n",
        "  NMI:        {hier_nmi:.4f}\n",
        "  ARI:        {hier_ari:.4f}\n",
        "\"\"\"\n",
        "axes[1, 2].text(0.1, 0.5, metrics_text, fontsize=11, family='monospace',\n",
        "                verticalalignment='center',\n",
        "                bbox=dict(boxstyle='round', facecolor='lightyellow', alpha=0.8))\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('images/clustering_analysis.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "060eacfb",
      "metadata": {
        "id": "060eacfb"
      },
      "source": [
        "From the analysis we have:\n",
        "- K-Means: NMI ≈ 0.74, ARI ≈ 0.39, Silhouette ≈ 0.02  \n",
        "- Hierarchical: NMI ≈ 0.73, ARI ≈ 0.41, Silhouette ≈ 0.02  \n",
        "\n",
        "Essentially, this means features carry strong semantic signal (high NMI) but cluster boundaries are soft and harder to see (low silhouette).\n",
        "\n",
        "There are some rigid shapes and centered objects (airplanes, towers, faces) and strong textures (zebra, sunflower) cluster well.\n",
        "However we can also see large/heterogeneous classes (clutter, people) spread across feature space and connect other groups. This also leads to some confused, visually similar classes (bikes vs. motorbikes, similar animal species) which mix frequently.\n",
        "\n",
        "When it comes to the dataset, class imbalance (≈10.6×) and ~28% zero entries in features likely reduce separability.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0be2a4fe",
      "metadata": {
        "id": "0be2a4fe"
      },
      "source": [
        "## Section 5: Deep Learning\n",
        "\n",
        "In this section, we explore the semantic structure of the visual feature space. By training an Artificial Neural Network using the features we extracted earlier with the pre-trained model. By building a neural network we can find more patterns in the data of the images by analysing the layers, to see which features are recognised most frequently and which are most hard to tell. Once we have our ANN, we'll analyse where it fails (Confusion Matrix, Misclassifications) and reveal from that analysis what visual concepts are most similar and most ambigous."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5321829b",
      "metadata": {
        "id": "5321829b"
      },
      "source": [
        "### Model Architecture and Preparation for Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ea5d90e",
      "metadata": {
        "id": "2ea5d90e"
      },
      "outputs": [],
      "source": [
        "# --- Constants ---\n",
        "FEATURE_DIMENSION = 1280\n",
        "NB_CATEGORIES = 233     # Number of folders in dataset\n",
        "EPOCHS = 50\n",
        "BATCH_SIZE = 64\n",
        "PATIENCE = 10\n",
        "OPTIMIZER = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "\n",
        "print(f\"Feature Dimension: {FEATURE_DIMENSION}\")\n",
        "print(f\"Number of Categories: {NB_CATEGORIES}\")\n",
        "print(f\"Training samples: {len(X_train)}\")\n",
        "print(f\"Validation samples: {len(X_val)}\")\n",
        "print(f\"Test samples: {len(X_test)}\")\n",
        "\n",
        "# Convert integer labels to one-hot encoding for Softmax output layer\n",
        "y_train_one_hot = to_categorical(y_train, NB_CATEGORIES)\n",
        "y_val_one_hot = to_categorical(y_val, NB_CATEGORIES)\n",
        "y_test_one_hot = to_categorical(y_test, NB_CATEGORIES)\n",
        "\n",
        "print(f\"\\nOne-hot encoded label shapes:\")\n",
        "print(f\"y_train_one_hot: {y_train_one_hot.shape}\")\n",
        "print(f\"y_val_one_hot: {y_val_one_hot.shape}\")\n",
        "print(f\"y_test_one_hot: {y_test_one_hot.shape}\")\n",
        "\n",
        "# MODEL DEFINITION: Deep Dense Network (PatternMind Architecture)\n",
        "def build_patternmind_net(input_dim, classes):\n",
        "    \"\"\"\n",
        "    Builds a deep dense network for high-dimensional feature classification.\n",
        "\n",
        "    Architecture Design:\n",
        "    - Layer 1 (512 units): High capacity to capture complex feature interactions\n",
        "    - Layer 2 (256 units): Medium capacity for intermediate representations\n",
        "    - Layer 3 (128 units): Lower capacity to consolidate learned patterns\n",
        "    - Output Layer (softmax): Multi-class probability distribution\n",
        "\n",
        "    Regularization:\n",
        "    - BatchNormalization: Stabilizes training by normalizing layer inputs\n",
        "    - Dropout (0.5, 0.3): Prevents overfitting by randomly dropping connections\n",
        "\n",
        "    Returns:\n",
        "        Compiled Keras Sequential model\n",
        "    \"\"\"\n",
        "    model = Sequential(name=\"PatternMind_ANN\")\n",
        "\n",
        "    # Layer 1: High capacity hidden layer\n",
        "    model.add(Dense(units=512, activation='relu', input_shape=(input_dim,)))\n",
        "    model.add(BatchNormalization())  # Stabilize training\n",
        "    model.add(Dropout(0.5))          # Prevent overfitting\n",
        "\n",
        "    # Layer 2: Medium capacity hidden layer\n",
        "    model.add(Dense(units=256, activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.5))\n",
        "\n",
        "    # Layer 3: Lower capacity layer\n",
        "    model.add(Dense(units=128, activation='relu'))\n",
        "    model.add(Dropout(0.3))\n",
        "\n",
        "    # Output Layer (Softmax for multi-class probability distribution)\n",
        "    model.add(Dense(units=classes, activation='softmax', name='output_classification'))\n",
        "\n",
        "    return model\n",
        "\n",
        "# Build the model\n",
        "patternmind_model = build_patternmind_net(FEATURE_DIMENSION, NB_CATEGORIES)\n",
        "\n",
        "# Print Model Summary\n",
        "patternmind_model.summary()\n",
        "\n",
        "# COMPILATION AND TRAINING SETUP\n",
        "patternmind_model.compile(\n",
        "    optimizer=OPTIMIZER,\n",
        "    loss='categorical_crossentropy',  # Standard loss for multi-class classification\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Early Stopping callback to halt training when validation loss plateaus\n",
        "es_callback = EarlyStopping(\n",
        "    monitor='val_loss',        # Monitor validation loss\n",
        "    patience=PATIENCE,         # Wait 10 epochs before stopping\n",
        "    restore_best_weights=True, # Restore weights from best epoch\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "print(\"Model Architecture Defined and Compiled.\")\n",
        "print(f\"\\nTraining Configuration:\")\n",
        "print(f\"  Optimizer: Adam (lr=0.001)\")\n",
        "print(f\"  Loss Function: Categorical Crossentropy\")\n",
        "print(f\"  Batch Size: {BATCH_SIZE}\")\n",
        "print(f\"  Max Epochs: {EPOCHS}\")\n",
        "print(f\"  Early Stopping Patience: {PATIENCE} epochs\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8e2b7a78",
      "metadata": {
        "id": "8e2b7a78"
      },
      "source": [
        "### ANN Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "117a76b7",
      "metadata": {
        "id": "117a76b7"
      },
      "outputs": [],
      "source": [
        "# Train the model\n",
        "print(\"Starting model training...\\n\")\n",
        "\n",
        "history = patternmind_model.fit(\n",
        "    X_train, y_train_one_hot,\n",
        "    epochs=EPOCHS,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    validation_data=(X_val, y_val_one_hot),\n",
        "    callbacks=[es_callback],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "print(\"\\n\" + \".\"*60)\n",
        "print(\"Training Complete!\")\n",
        "print(\".\"*60)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4b3cd495",
      "metadata": {
        "id": "4b3cd495"
      },
      "source": [
        "### ANN Training Visualization\n",
        "\n",
        "Visualize the training progress showing accuracy and loss curves for both training and validation sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f84b36fd",
      "metadata": {
        "id": "f84b36fd"
      },
      "outputs": [],
      "source": [
        "# Visualize training history\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Plot training & validation accuracy\n",
        "axes[0].plot(history.history['accuracy'], label='Training Accuracy', linewidth=2)\n",
        "axes[0].plot(history.history['val_accuracy'], label='Validation Accuracy', linewidth=2)\n",
        "axes[0].set_title('Model Accuracy Over Epochs', fontsize=14, fontweight='bold')\n",
        "axes[0].set_xlabel('Epoch', fontsize=12)\n",
        "axes[0].set_ylabel('Accuracy', fontsize=12)\n",
        "axes[0].legend(loc='lower right', fontsize=10)\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "# Plot training & validation loss\n",
        "axes[1].plot(history.history['loss'], label='Training Loss', linewidth=2)\n",
        "axes[1].plot(history.history['val_loss'], label='Validation Loss', linewidth=2)\n",
        "axes[1].set_title('Model Loss Over Epochs', fontsize=14, fontweight='bold')\n",
        "axes[1].set_xlabel('Epoch', fontsize=12)\n",
        "axes[1].set_ylabel('Loss', fontsize=12)\n",
        "axes[1].legend(loc='upper right', fontsize=10)\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('images/ann_training_history.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "# Print final metrics\n",
        "final_train_acc = history.history['accuracy'][-1]\n",
        "final_val_acc = history.history['val_accuracy'][-1]\n",
        "final_train_loss = history.history['loss'][-1]\n",
        "final_val_loss = history.history['val_loss'][-1]\n",
        "\n",
        "print(f\"\\nFinal ANN Training Metrics:\")\n",
        "print(f\"  Training Accuracy:   {final_train_acc:.4f}\")\n",
        "print(f\"  Training Loss:       {final_train_loss:.4f}\")\n",
        "print(f\"  Validation Accuracy: {final_val_acc:.4f}\")\n",
        "print(f\"  Validation Loss:     {final_val_loss:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Structural Analysis, Evaluation\n",
        "\n",
        "The objective of the Neural net was to reveal the semantic structure of the dataset, to explore where and why the model makes mistakes. For our research these mistakes are exactly what we're looking for, they're windows into the ambiguity that arises from similar features, and help us better understand the relationship between visual concepts."
      ],
      "metadata": {
        "id": "Kr94kxrzrwYH"
      },
      "id": "Kr94kxrzrwYH"
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate on test set\n",
        "test_loss, test_accuracy = patternmind_model.evaluate(X_test, y_test_one_hot, verbose=0)\n",
        "\n",
        "print(\".\"*60)\n",
        "print(\"TEST SET EVALUATION\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
        "print(f\"Test Loss:     {test_loss:.4f}\")\n",
        "print(\".\"*60)\n",
        "\n",
        "# Get predictions\n",
        "y_pred_probs = patternmind_model.predict(X_test, verbose=0)\n",
        "y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "\n",
        "# Generate comprehensive classification report\n",
        "print(\"\\n\" + \".\"*60)\n",
        "print(\"COMPREHENSIVE CLASSIFICATION REPORT\")\n",
        "print(\".\"*60)\n",
        "print(\"\\nThis report reveals which categories the model struggles to distinguish,\")\n",
        "print(\"highlighting areas of ambiguity in the visual feature space.\\n\")\n",
        "\n",
        "# Get category names for the report\n",
        "category_names = label_encoder.classes_\n",
        "\n",
        "# Generate detailed classification report\n",
        "report = classification_report(\n",
        "    y_test,\n",
        "    y_pred,\n",
        "    target_names=category_names,\n",
        "    digits=4\n",
        ")\n",
        "\n",
        "print(report)"
      ],
      "metadata": {
        "id": "yB7CSkW0sZ1B"
      },
      "id": "yB7CSkW0sZ1B",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Confusion Matrix\n",
        "\n",
        "We will use a confusion matrix to visualise which misclassifications happen most often, to interpret this confusion matrix one must look at the off diagonal elements, the elements that form the diagonal are the elements that are correctly classified."
      ],
      "metadata": {
        "id": "XAzNQskTt2uK"
      },
      "id": "XAzNQskTt2uK"
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Visualize confusion matrix\n",
        "fig, ax = plt.subplots(figsize=(16, 14))\n",
        "\n",
        "# Create heatmap\n",
        "sns.heatmap(\n",
        "    cm,\n",
        "    annot=True,           # Show numbers in cells\n",
        "    fmt='d',              # Integer format\n",
        "    cmap='YlOrRd',        # Yellow-Orange-Red colormap\n",
        "    xticklabels=category_names,\n",
        "    yticklabels=category_names,\n",
        "    cbar_kws={'label': 'Number of Predictions'},\n",
        "    linewidths=0.5,\n",
        "    linecolor='gray',\n",
        "    ax=ax\n",
        ")\n",
        "\n",
        "ax.set_title('Confusion Matrix: Revealing Visual Category Relationships',\n",
        "             fontsize=16, fontweight='bold', pad=20)\n",
        "ax.set_xlabel('Predicted Category', fontsize=13, fontweight='bold')\n",
        "ax.set_ylabel('True Category', fontsize=13, fontweight='bold')\n",
        "\n",
        "# Rotate labels for better readability\n",
        "plt.xticks(rotation=45, ha='right', fontsize=5)\n",
        "plt.yticks(rotation=0, fontsize=5)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('images/confusion_matrix.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cUy1nFiuuPd-"
      },
      "id": "cUy1nFiuuPd-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This visualisation is certainly useful, but let's look at the worst offenders."
      ],
      "metadata": {
        "id": "To--wRkQwVfr"
      },
      "id": "To--wRkQwVfr"
    },
    {
      "cell_type": "code",
      "source": [
        "# Find top misclassification pairs (excluding correct predictions on diagonal)\n",
        "misclassifications = []\n",
        "\n",
        "for i in range(len(cm)):\n",
        "    for j in range(len(cm)):\n",
        "        if i != j and cm[i, j] > 0:  # Off-diagonal elements only\n",
        "            misclassifications.append({\n",
        "                'true_category': category_names[i],\n",
        "                'predicted_category': category_names[j],\n",
        "                'count': cm[i, j],\n",
        "                'true_idx': i,\n",
        "                'pred_idx': j\n",
        "            })\n",
        "\n",
        "# Sort by count\n",
        "misclassifications.sort(key=lambda x: x['count'], reverse=True)\n",
        "\n",
        "# Display top 20 misclassification pairs\n",
        "print(\".\"*80)\n",
        "print(\"TOP 20 MISCLASSIFICATION PAIRS\")\n",
        "print(\".\"*80)\n",
        "print(f\"{'Rank':<6} {'True Category':<20} {'-> Predicted As':<20} {'Count':<8} {'Pattern'}\")\n",
        "print(\"-\"*80)\n",
        "\n",
        "for rank, mc in enumerate(misclassifications[:20], 1):\n",
        "    print(f\"{rank:<6} {mc['true_category']:<20} → {mc['predicted_category']:<20} {mc['count']:<8}\")\n",
        "\n",
        "# Find indices of misclassified samples\n",
        "misclassified_indices = np.where(y_test != y_pred)[0]\n",
        "\n",
        "print(f\"\\n Total misclassified samples: {len(misclassified_indices)}\")\n",
        "print(f\"Total test samples: {len(y_test)}\")\n",
        "print(f\"Misclassification rate: {len(misclassified_indices)/len(y_test)*100:.2f}%\\n\")\n",
        "\n",
        "# Get the prediction confidence (probability) for misclassified samples\n",
        "misclassified_confidences = []\n",
        "for idx in misclassified_indices:\n",
        "    pred_prob = y_pred_probs[idx, y_pred[idx]]  # Probability of predicted class\n",
        "    misclassified_confidences.append({\n",
        "        'idx': idx,\n",
        "        'true_label': y_test[idx],\n",
        "        'pred_label': y_pred[idx],\n",
        "        'confidence': pred_prob,\n",
        "        'true_name': category_names[y_test[idx]],\n",
        "        'pred_name': category_names[y_pred[idx]]\n",
        "    })\n",
        "\n",
        "# Sort by confidence (high confidence errors are most interesting)\n",
        "misclassified_confidences.sort(key=lambda x: x['confidence'], reverse=True)\n",
        "\n",
        "# Select top 16 most confident misclassifications for visualization\n",
        "num_to_display = min(16, len(misclassified_confidences))\n",
        "samples_to_show = misclassified_confidences[:num_to_display]\n",
        "\n",
        "print(f\"Displaying {num_to_display} most confident misclassifications...\")\n",
        "print(\"(High confidence errors reveal strong structural similarity)\\n\")"
      ],
      "metadata": {
        "id": "Hwdv6GVywekc"
      },
      "id": "Hwdv6GVywekc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualising Ambiguity\n",
        "\n",
        "By exploring the misclassified samples we can find out 'why' certain categories are or aren't semantically similar in the feature space"
      ],
      "metadata": {
        "id": "kQpt2OE4xudK"
      },
      "id": "kQpt2OE4xudK"
    },
    {
      "cell_type": "code",
      "source": [
        "# Find indices of misclassified samples\n",
        "misclassified_indices = np.where(y_test != y_pred)[0]\n",
        "\n",
        "print(f\"Total misclassified samples: {len(misclassified_indices)}\")\n",
        "print(f\"Total test samples: {len(y_test)}\")\n",
        "print(f\"Misclassification rate: {len(misclassified_indices)/len(y_test)*100:.2f}%\\n\")\n",
        "\n",
        "# Get the prediction confidence (probability) for misclassified samples\n",
        "misclassified_confidences = []\n",
        "for idx in misclassified_indices:\n",
        "    pred_prob = y_pred_probs[idx, y_pred[idx]]  # Probability of predicted class\n",
        "    misclassified_confidences.append({\n",
        "        'idx': idx,\n",
        "        'true_label': y_test[idx],\n",
        "        'pred_label': y_pred[idx],\n",
        "        'confidence': pred_prob,\n",
        "        'true_name': category_names[y_test[idx]],\n",
        "        'pred_name': category_names[y_pred[idx]]\n",
        "    })\n",
        "\n",
        "# Sort by confidence (high confidence errors are most interesting)\n",
        "misclassified_confidences.sort(key=lambda x: x['confidence'], reverse=True)\n",
        "\n",
        "# Select top 16 most confident misclassifications for visualization\n",
        "num_to_display = min(16, len(misclassified_confidences))\n",
        "samples_to_show = misclassified_confidences[:num_to_display]\n",
        "\n",
        "print(f\"Displaying {num_to_display} most confident misclassifications...\")\n",
        "print(\"(High confidence errors reveal strong structural similarity)\\n\")"
      ],
      "metadata": {
        "id": "OL7Yoq3kyYto"
      },
      "id": "OL7Yoq3kyYto",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "xNfmEZTPy_xz"
      },
      "id": "xNfmEZTPy_xz"
    },
    {
      "cell_type": "code",
      "source": [
        "sns.set_style(\"whitegrid\")\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "# Create figure with multiple subplots\n",
        "fig = plt.figure(figsize=(20, 12))\n",
        "gs = fig.add_gridspec(3, 2, hspace=0.3, wspace=0.3)\n",
        "\n",
        "# 1. Confidence Distribution of Misclassifications\n",
        "ax1 = fig.add_subplot(gs[0, :])\n",
        "confidences = [s['confidence'] * 100 for s in misclassified_confidences]\n",
        "\n",
        "sns.histplot(confidences, bins=30, kde=True, ax=ax1, color='coral', alpha=0.7)\n",
        "ax1.axvline(np.mean(confidences), color='red', linestyle='--', linewidth=2,\n",
        "            label=f'Mean: {np.mean(confidences):.1f}%')\n",
        "ax1.axvline(np.median(confidences), color='darkred', linestyle=':', linewidth=2,\n",
        "            label=f'Median: {np.median(confidences):.1f}%')\n",
        "ax1.set_xlabel('Prediction Confidence (%)', fontsize=12, fontweight='bold')\n",
        "ax1.set_ylabel('Count', fontsize=12, fontweight='bold')\n",
        "ax1.set_title('Distribution of Confidence Scores for Misclassifications',\n",
        "              fontsize=14, fontweight='bold', pad=20)\n",
        "ax1.legend(fontsize=11)\n",
        "ax1.grid(alpha=0.3)\n",
        "\n",
        "# 2. Top 15 Most Misclassified Categories (True Labels)\n",
        "ax2 = fig.add_subplot(gs[1, 0])\n",
        "\n",
        "# Count misclassifications by true category\n",
        "true_category_errors = {}\n",
        "for sample in misclassified_confidences:\n",
        "    true_cat = sample['true_name']\n",
        "    true_category_errors[true_cat] = true_category_errors.get(true_cat, 0) + 1\n",
        "\n",
        "# Sort and get top 15\n",
        "true_sorted = sorted(true_category_errors.items(), key=lambda x: x[1], reverse=True)[:15]\n",
        "true_df = pd.DataFrame(true_sorted, columns=['Category', 'Error Count'])\n",
        "\n",
        "# Create horizontal bar plot\n",
        "sns.barplot(data=true_df, y='Category', x='Error Count', ax=ax2,\n",
        "            palette='Reds_r', orient='h')\n",
        "ax2.set_xlabel('Number of Misclassifications', fontsize=11, fontweight='bold')\n",
        "ax2.set_ylabel('True Category', fontsize=11, fontweight='bold')\n",
        "ax2.set_title('Top 15 Categories Most Often Misclassified\\n(Hardest to Identify Correctly)',\n",
        "              fontsize=12, fontweight='bold', pad=15)\n",
        "ax2.grid(axis='x', alpha=0.3)\n",
        "\n",
        "# Add value labels on bars\n",
        "for i, (idx, row) in enumerate(true_df.iterrows()):\n",
        "    ax2.text(row['Error Count'] + 0.5, i, str(row['Error Count']),\n",
        "             va='center', fontsize=9, fontweight='bold')\n",
        "\n",
        "# 3. Top 15 Most Over-Predicted Categories (Predicted Labels)\n",
        "ax3 = fig.add_subplot(gs[1, 1])\n",
        "\n",
        "# Count by predicted category\n",
        "pred_category_errors = {}\n",
        "for sample in misclassified_confidences:\n",
        "    pred_cat = sample['pred_name']\n",
        "    pred_category_errors[pred_cat] = pred_category_errors.get(pred_cat, 0) + 1\n",
        "\n",
        "# Sort and get top 15\n",
        "pred_sorted = sorted(pred_category_errors.items(), key=lambda x: x[1], reverse=True)[:15]\n",
        "pred_df = pd.DataFrame(pred_sorted, columns=['Category', 'Count'])\n",
        "\n",
        "# Create horizontal bar plot\n",
        "sns.barplot(data=pred_df, y='Category', x='Count', ax=ax3,\n",
        "            palette='Blues_r', orient='h')\n",
        "ax3.set_xlabel('Number of Times Predicted', fontsize=11, fontweight='bold')\n",
        "ax3.set_ylabel('Predicted Category', fontsize=11, fontweight='bold')\n",
        "ax3.set_title('Top 15 Categories Most Often Over-Predicted\\n(Model Tends to Over-Predict These)',\n",
        "              fontsize=12, fontweight='bold', pad=15)\n",
        "ax3.grid(axis='x', alpha=0.3)\n",
        "\n",
        "# Add value labels on bars\n",
        "for i, (idx, row) in enumerate(pred_df.iterrows()):\n",
        "    ax3.text(row['Count'] + 0.5, i, str(row['Count']),\n",
        "             va='center', fontsize=9, fontweight='bold')\n",
        "\n",
        "# Sample misclassification\n",
        "ax4 = fig.add_subplot(gs[2, :])\n",
        "\n",
        "# Get top 20 samples with highest confidence\n",
        "samples_to_show = sorted(misclassified_confidences,\n",
        "                        key=lambda x: x['confidence'],\n",
        "                        reverse=True)[:20]\n",
        "\n",
        "# Prepare data\n",
        "sample_nums = list(range(1, len(samples_to_show) + 1))\n",
        "confidences_sample = [s['confidence'] * 100 for s in samples_to_show]\n",
        "labels = [f\"{s['true_name'][:20]}→{s['pred_name'][:20]}\" for s in samples_to_show]\n",
        "\n",
        "# Create bar plot\n",
        "colors = sns.color_palette(\"RdYlGn_r\", len(samples_to_show))\n",
        "bars = ax4.barh(sample_nums, confidences_sample, color=colors, alpha=0.8, edgecolor='black')\n",
        "\n",
        "ax4.set_yticks(sample_nums)\n",
        "ax4.set_yticklabels([f\"#{i}\" for i in sample_nums], fontsize=9)\n",
        "ax4.set_xlabel('Prediction Confidence (%)', fontsize=11, fontweight='bold')\n",
        "ax4.set_ylabel('Sample #', fontsize=11, fontweight='bold')\n",
        "ax4.set_title('Top 20 High-Confidence Misclassifications',\n",
        "              fontsize=12, fontweight='bold', pad=15)\n",
        "ax4.grid(axis='x', alpha=0.3)\n",
        "ax4.invert_yaxis()\n",
        "\n",
        "# Add confidence values on bars\n",
        "for i, (bar, conf) in enumerate(zip(bars, confidences_sample)):\n",
        "    ax4.text(conf + 1, bar.get_y() + bar.get_height()/2,\n",
        "             f'{conf:.1f}%', va='center', fontsize=8, fontweight='bold')\n",
        "\n",
        "# Add overall statistics as text box\n",
        "total_misclass = len(misclassified_confidences)\n",
        "avg_conf = np.mean([s['confidence'] * 100 for s in misclassified_confidences])\n",
        "median_conf = np.median([s['confidence'] * 100 for s in misclassified_confidences])\n",
        "\n",
        "stats_text = f\"\"\"OVERALL STATISTICS\n",
        "─────────────────────\n",
        "Total Misclassifications: {total_misclass:,}\n",
        "Average Confidence: {avg_conf:.1f}%\n",
        "Median Confidence: {median_conf:.1f}%\n",
        "Unique True Categories: {len(true_category_errors)}\n",
        "Unique Predicted Categories: {len(pred_category_errors)}\"\"\"\n",
        "\n",
        "fig.text(0.98, 0.02, stats_text, fontsize=10, family='monospace',\n",
        "         bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8),\n",
        "         verticalalignment='bottom', horizontalalignment='right')\n",
        "\n",
        "# Main title\n",
        "fig.suptitle('Detailed Misclassification Analysis Dashboard',\n",
        "             fontsize=16, fontweight='bold', y=0.995)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wmnZQC2kzAIf"
      },
      "id": "wmnZQC2kzAIf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Per Category Analysis"
      ],
      "metadata": {
        "id": "g0wgUbCXzVeb"
      },
      "id": "g0wgUbCXzVeb"
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract per-class metrics\n",
        "precision, recall, f1, support = precision_recall_fscore_support(\n",
        "    y_test, y_pred, labels=range(len(category_names)), zero_division=0\n",
        ")\n",
        "\n",
        "# Create DataFrame\n",
        "performance_df = pd.DataFrame({\n",
        "    'Category': category_names,\n",
        "    'Precision': precision,\n",
        "    'Recall': recall,\n",
        "    'F1-Score': f1,\n",
        "    'Support': support\n",
        "})\n",
        "\n",
        "# Sort by F1-score\n",
        "performance_df_sorted = performance_df.sort_values('F1-Score', ascending=False)\n",
        "\n",
        "# Set style\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.rcParams['figure.facecolor'] = 'white'\n",
        "\n",
        "# Create figure with multiple subplots\n",
        "fig = plt.figure(figsize=(22, 14))\n",
        "gs = fig.add_gridspec(3, 3, hspace=0.35, wspace=0.3)\n",
        "\n",
        "# 1. F1-Score Distribution (KDE + Histogram)\n",
        "ax1 = fig.add_subplot(gs[0, :])\n",
        "\n",
        "sns.histplot(performance_df['F1-Score'], bins=40, kde=True, ax=ax1,\n",
        "             color='steelblue', alpha=0.7, edgecolor='black')\n",
        "\n",
        "# Add mean and median lines\n",
        "mean_f1 = performance_df['F1-Score'].mean()\n",
        "median_f1 = performance_df['F1-Score'].median()\n",
        "ax1.axvline(mean_f1, color='red', linestyle='--', linewidth=2.5,\n",
        "            label=f'Mean: {mean_f1:.3f}')\n",
        "ax1.axvline(median_f1, color='darkred', linestyle=':', linewidth=2.5,\n",
        "            label=f'Median: {median_f1:.3f}')\n",
        "\n",
        "# Add threshold zones\n",
        "ax1.axvspan(0, 0.3, alpha=0.1, color='red', label='Poor (<0.30)')\n",
        "ax1.axvspan(0.3, 0.5, alpha=0.1, color='orange', label='Below Average (0.30-0.50)')\n",
        "ax1.axvspan(0.8, 1.0, alpha=0.1, color='green', label='Excellent (>0.80)')\n",
        "\n",
        "ax1.set_xlabel('F1-Score', fontsize=13, fontweight='bold')\n",
        "ax1.set_ylabel('Number of Categories', fontsize=13, fontweight='bold')\n",
        "ax1.set_title('Distribution of F1-Scores Across All Categories',\n",
        "              fontsize=15, fontweight='bold', pad=20)\n",
        "ax1.legend(fontsize=11, loc='upper left')\n",
        "ax1.grid(alpha=0.3)\n",
        "\n",
        "# 2. Top 15 Best Performing Categories\n",
        "ax2 = fig.add_subplot(gs[1, :2])\n",
        "\n",
        "top_15 = performance_df_sorted.head(15)\n",
        "colors_top = sns.color_palette(\"Greens_r\", len(top_15))\n",
        "\n",
        "bars = ax2.barh(range(len(top_15)), top_15['F1-Score'], color=colors_top,\n",
        "                alpha=0.8, edgecolor='darkgreen', linewidth=1.5)\n",
        "ax2.set_yticks(range(len(top_15)))\n",
        "ax2.set_yticklabels(top_15['Category'], fontsize=10)\n",
        "ax2.set_xlabel('F1-Score', fontsize=12, fontweight='bold')\n",
        "ax2.set_title('🏆 Top 15 Best Performing Categories', fontsize=13, fontweight='bold', pad=15)\n",
        "ax2.set_xlim(0, 1.05)\n",
        "ax2.invert_yaxis()\n",
        "ax2.grid(axis='x', alpha=0.3)\n",
        "\n",
        "# Add value labels\n",
        "for i, (v, support) in enumerate(zip(top_15['F1-Score'], top_15['Support'])):\n",
        "    ax2.text(v + 0.01, i, f'{v:.3f} (n={int(support)})',\n",
        "             va='center', fontsize=9, fontweight='bold')\n",
        "\n",
        "# 3. Performance Summary Stats Box\n",
        "ax3 = fig.add_subplot(gs[1, 2])\n",
        "ax3.axis('off')\n",
        "\n",
        "# Calculate stats\n",
        "high_perf = len(performance_df[performance_df['F1-Score'] > 0.80])\n",
        "mid_perf = len(performance_df[(performance_df['F1-Score'] >= 0.50) & (performance_df['F1-Score'] <= 0.80)])\n",
        "low_perf = len(performance_df[(performance_df['F1-Score'] >= 0.30) & (performance_df['F1-Score'] < 0.50)])\n",
        "poor_perf = len(performance_df[performance_df['F1-Score'] < 0.30])\n",
        "\n",
        "stats_text = f\"\"\"\n",
        "PERFORMANCE STATISTICS\n",
        "{'='*40}\n",
        "\n",
        "F1-SCORE DISTRIBUTION\n",
        "  Mean:        {performance_df['F1-Score'].mean():.4f}\n",
        "  Median:      {performance_df['F1-Score'].median():.4f}\n",
        "  Std Dev:     {performance_df['F1-Score'].std():.4f}\n",
        "  Min:         {performance_df['F1-Score'].min():.4f}\n",
        "  Max:         {performance_df['F1-Score'].max():.4f}\n",
        "\n",
        "CATEGORY BREAKDOWN\n",
        "  Excellent (>0.80):      {high_perf:>3} categories\n",
        "  Good (0.50-0.80):       {mid_perf:>3} categories\n",
        "  Below Avg (0.30-0.50):  {low_perf:>3} categories\n",
        "  Poor (<0.30):           {poor_perf:>3} categories\n",
        "\n",
        "  Total Categories:       {len(performance_df):>3}\n",
        "\n",
        "METRIC AVERAGES\n",
        "  Avg Precision:   {performance_df['Precision'].mean():.4f}\n",
        "  Avg Recall:      {performance_df['Recall'].mean():.4f}\n",
        "  Avg F1-Score:    {performance_df['F1-Score'].mean():.4f}\n",
        "\"\"\"\n",
        "\n",
        "ax3.text(0.05, 0.95, stats_text, transform=ax3.transAxes,\n",
        "         fontsize=10, verticalalignment='top', family='monospace',\n",
        "         bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.8, pad=1))\n",
        "\n",
        "# 4. Bottom 15 Worst Performing Categories\n",
        "ax4 = fig.add_subplot(gs[2, :2])\n",
        "\n",
        "bottom_15 = performance_df_sorted.tail(15).sort_values('F1-Score', ascending=False)\n",
        "colors_bottom = sns.color_palette(\"Reds_r\", len(bottom_15))\n",
        "\n",
        "bars = ax4.barh(range(len(bottom_15)), bottom_15['F1-Score'], color=colors_bottom,\n",
        "                alpha=0.8, edgecolor='darkred', linewidth=1.5)\n",
        "ax4.set_yticks(range(len(bottom_15)))\n",
        "ax4.set_yticklabels(bottom_15['Category'], fontsize=10)\n",
        "ax4.set_xlabel('F1-Score', fontsize=12, fontweight='bold')\n",
        "ax4.set_title('⚠️  Bottom 15 Worst Performing Categories', fontsize=13, fontweight='bold', pad=15)\n",
        "ax4.set_xlim(0, max(0.5, bottom_15['F1-Score'].max() + 0.05))\n",
        "ax4.invert_yaxis()\n",
        "ax4.grid(axis='x', alpha=0.3)\n",
        "\n",
        "# Add value labels\n",
        "for i, (v, support) in enumerate(zip(bottom_15['F1-Score'], bottom_15['Support'])):\n",
        "    ax4.text(v + 0.01, i, f'{v:.3f} (n={int(support)})',\n",
        "             va='center', fontsize=9, fontweight='bold')\n",
        "\n",
        "# 5. Precision vs Recall Scatter Plot\n",
        "ax5 = fig.add_subplot(gs[2, 2])\n",
        "\n",
        "# Color by F1-Score\n",
        "scatter = ax5.scatter(performance_df['Precision'], performance_df['Recall'],\n",
        "                     c=performance_df['F1-Score'], s=performance_df['Support']/2,\n",
        "                     cmap='RdYlGn', alpha=0.6, edgecolors='black', linewidth=0.5)\n",
        "\n",
        "ax5.plot([0, 1], [0, 1], 'k--', alpha=0.3, linewidth=1)\n",
        "ax5.set_xlabel('Precision', fontsize=12, fontweight='bold')\n",
        "ax5.set_ylabel('Recall', fontsize=12, fontweight='bold')\n",
        "ax5.set_title('Precision vs Recall\\n(Size = Support, Color = F1)',\n",
        "              fontsize=11, fontweight='bold', pad=15)\n",
        "ax5.set_xlim(-0.05, 1.05)\n",
        "ax5.set_ylim(-0.05, 1.05)\n",
        "ax5.grid(alpha=0.3)\n",
        "\n",
        "# Add colorbar\n",
        "cbar = plt.colorbar(scatter, ax=ax5)\n",
        "cbar.set_label('F1-Score', fontsize=10, fontweight='bold')\n",
        "\n",
        "# Main title\n",
        "fig.suptitle('Per-Category Performance Analysis Dashboard',\n",
        "             fontsize=17, fontweight='bold', y=0.995)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('images/category_performance_seaborn.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "extB7NRrzySV"
      },
      "id": "extB7NRrzySV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusions"
      ],
      "metadata": {
        "id": "d3Zn8Iu50GAM"
      },
      "id": "d3Zn8Iu50GAM"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}