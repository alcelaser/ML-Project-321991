{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48f90a71",
   "metadata": {},
   "source": [
    "# Visual Concept Analysis: Exploring Semantic Structures in Image Collections\n",
    "\n",
    " A inital analysis of the dataset to uncover visual patterns, clusters, and relationships among image categories. The focus is mianly on understanding and organizing the visual space."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece6bdc6",
   "metadata": {},
   "source": [
    "## Section 1: Environment Setup and Data Loading\n",
    "\n",
    "In this section, we will:\n",
    "- Import all necessary libraries for data manipulation, visualization, and machine learning\n",
    "- Load the dataset\n",
    "- Perform initial data inspection to understand the structure, dimensions, and basic characteristics of our dataset\n",
    "\n",
    "The libraries selected cover essential functionalities:\n",
    "- **Data handling**: pandas, numpy for efficient data structures and numerical operations\n",
    "- **Visualization**: matplotlib, seaborn, plotly for exploratory and publication-quality visualizations\n",
    "- **Machine Learning**: scikit-learn for preprocessing, modeling, and evaluation and keras for neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008ff685",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import core libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import warnings\n",
    "import os\n",
    "from pathlib import Path\n",
    "import glob\n",
    "\n",
    "# Image processing libraries\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "# Sklearn preprocessing\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, RobustScaler\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "\n",
    "# Sklearn model selection\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, StratifiedKFold\n",
    "\n",
    "# Sklearn metrics\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, accuracy_score, \n",
    "    precision_score, recall_score, f1_score, roc_auc_score, roc_curve,\n",
    "    silhouette_score, davies_bouldin_score, calinski_harabasz_score\n",
    ")\n",
    "\n",
    "# Models for classification/clustering\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.cluster import KMeans, DBSCAN, AgglomerativeClustering\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Deep Learning for feature extraction\n",
    "try:\n",
    "    import tensorflow as tf\n",
    "    from tensorflow.keras.applications import VGG16, ResNet50, MobileNetV2\n",
    "    from tensorflow.keras.applications.vgg16 import preprocess_input as vgg16_preprocess\n",
    "    from tensorflow.keras.applications.resnet50 import preprocess_input as resnet_preprocess\n",
    "    from tensorflow.keras.applications.mobilenet_v2 import preprocess_input as mobilenet_preprocess\n",
    "    from tensorflow.keras.preprocessing import image\n",
    "    print(\"TensorFlow/Keras available for deep feature extraction\")\n",
    "except ImportError:\n",
    "    print(\"TensorFlow/Keras not available - will use traditional feature extraction\")\n",
    "\n",
    "# Configuration\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "%matplotlib inline\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "RANDOM_STATE = 69  # we're aware 42 is the industry standard, but 69 is cooler\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(f\"OpenCV version: {cv2.__version__}\")\n",
    "print(f\"PIL version: {Image.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f04889d",
   "metadata": {},
   "source": [
    "### 1.1 Load Image Dataset\n",
    "\n",
    "The patternmind_dataset is organized as a folder-based image collection where:\n",
    "- Each subfolder in `.data/` represents a distinct visual category\n",
    "- Images within each folder are labeled by their parent folder name\n",
    "- This is a hierarchical structure typical of image classification datasets\n",
    "\n",
    "We will:\n",
    "- Scan the `.data/` directory to identify all categories\n",
    "- Build a catalog (DataFrame) containing image paths and their corresponding labels\n",
    "- Calculate dataset statistics (number of categories, images per category, total images)\n",
    "\n",
    "Expected output: A DataFrame with columns for image paths and category labels, along with a summary showing the distribution of images across categories. This catalog will serve as the foundation for all subsequent analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93359d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the data directory\n",
    "DATA_DIR = Path('.data')\n",
    "\n",
    "# Initialize lists to store image paths and labels\n",
    "image_paths = []\n",
    "labels = []\n",
    "\n",
    "# Scan the data directory for category folders\n",
    "print(\"Scanning dataset directory...\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Get all category folders\n",
    "category_folders = [f for f in DATA_DIR.iterdir() if f.is_dir()]\n",
    "category_folders = sorted(category_folders)\n",
    "\n",
    "print(f\"Found {len(category_folders)} categories\")\n",
    "print(\"\\nScanning images in each category...\")\n",
    "\n",
    "# Iterate through each category folder\n",
    "for category_folder in category_folders:\n",
    "    category_name = category_folder.name\n",
    "    \n",
    "    # Find all image files in the category folder\n",
    "    # Support common image formats: jpg, jpeg, png, bmp\n",
    "    image_files = list(category_folder.glob('*.jpg')) + \\\n",
    "                  list(category_folder.glob('*.jpeg')) + \\\n",
    "                  list(category_folder.glob('*.png')) + \\\n",
    "                  list(category_folder.glob('*.bmp'))\n",
    "    \n",
    "    # Add to our lists\n",
    "    for img_path in image_files:\n",
    "        image_paths.append(str(img_path))\n",
    "        labels.append(category_name)\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'image_path': image_paths,\n",
    "    'category': labels\n",
    "})\n",
    "\n",
    "# Display basic information\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Dataset loaded successfully!\")\n",
    "print(\"=\"*50)\n",
    "print(f\"\\nDataset shape: {df.shape}\")\n",
    "print(f\"Total number of images: {df.shape[0]:,}\")\n",
    "print(f\"Number of categories: {df['category'].nunique()}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Category Distribution:\")\n",
    "print(\"=\"*50)\n",
    "category_counts = df['category'].value_counts().sort_index()\n",
    "print(f\"\\nImages per category (first 10):\")\n",
    "display(category_counts.head(10))\n",
    "\n",
    "print(f\"\\nStatistics:\")\n",
    "print(f\"  Mean images per category: {category_counts.mean():.1f}\")\n",
    "print(f\"  Median images per category: {category_counts.median():.1f}\")\n",
    "print(f\"  Min images per category: {category_counts.min()}\")\n",
    "print(f\"  Max images per category: {category_counts.max()}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"First few rows of the dataset:\")\n",
    "print(\"=\"*50)\n",
    "display(df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40f6eae",
   "metadata": {},
   "source": [
    "### 1.2 Dataset Overview and Validation\n",
    "\n",
    "Now we will validate the integrity of our image dataset by:\n",
    "- Checking for any corrupted or unreadable images\n",
    "- Verifying image dimensions and formats\n",
    "- Analyzing the distribution of images across categories\n",
    "- Identifying potential class imbalance issues\n",
    "\n",
    "We'll also create a sample visualization showing example images from random categories to visually confirm the dataset quality and diversity.\n",
    "\n",
    "Expected output: Summary statistics about image properties, a class distribution chart, and a grid of sample images from various categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945024a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample a few images to check dimensions and formats\n",
    "print(\"Analyzing image properties...\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "sample_size = min(100, len(df))\n",
    "sample_indices = np.random.choice(len(df), size=sample_size, replace=False)\n",
    "\n",
    "widths = []\n",
    "heights = []\n",
    "formats = []\n",
    "corrupted_images = []\n",
    "\n",
    "for idx in sample_indices:\n",
    "    img_path = df.iloc[idx]['image_path']\n",
    "    try:\n",
    "        img = Image.open(img_path)\n",
    "        widths.append(img.width)\n",
    "        heights.append(img.height)\n",
    "        formats.append(img.format)\n",
    "        img.close()\n",
    "    except Exception as e:\n",
    "        corrupted_images.append(img_path)\n",
    "        print(f\"Warning: Could not read {img_path}: {e}\")\n",
    "\n",
    "if len(corrupted_images) > 0:\n",
    "    print(f\"\\n⚠️ Found {len(corrupted_images)} corrupted images\")\n",
    "else:\n",
    "    print(\"\\n✓ All sampled images are valid\")\n",
    "\n",
    "print(f\"\\nImage Dimensions (from {sample_size} samples):\")\n",
    "print(f\"  Width  - Min: {min(widths)}px, Max: {max(widths)}px, Mean: {np.mean(widths):.1f}px\")\n",
    "print(f\"  Height - Min: {min(heights)}px, Max: {max(heights)}px, Mean: {np.mean(heights):.1f}px\")\n",
    "print(f\"\\nImage Formats: {set(formats)}\")\n",
    "\n",
    "# Analyze category distribution\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Category Distribution Analysis:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "category_counts = df['category'].value_counts()\n",
    "print(f\"\\nTop 10 most common categories:\")\n",
    "display(category_counts.head(10))\n",
    "\n",
    "print(f\"\\nTop 10 least common categories:\")\n",
    "display(category_counts.tail(10))\n",
    "\n",
    "# Check for class imbalance\n",
    "imbalance_ratio = category_counts.max() / category_counts.min()\n",
    "print(f\"\\nClass Imbalance Ratio: {imbalance_ratio:.2f}x\")\n",
    "if imbalance_ratio > 3:\n",
    "    print(\"⚠️ Significant class imbalance detected - consider stratified sampling\")\n",
    "else:\n",
    "    print(\"✓ Relatively balanced dataset\")\n",
    "\n",
    "# Store key information for later use\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Dataset Summary:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Total Images: {len(df):,}\")\n",
    "print(f\"Total Categories: {df['category'].nunique()}\")\n",
    "print(f\"Average Images per Category: {len(df) / df['category'].nunique():.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83755c7",
   "metadata": {},
   "source": [
    "### 1.3 Visualize Sample Images\n",
    "\n",
    "To better understand our dataset, we'll display a grid of sample images from different categories. This visual inspection helps us:\n",
    "- Verify that images are loading correctly\n",
    "- Understand the visual diversity within and across categories\n",
    "- Identify any obvious data quality issues\n",
    "- Get an intuitive sense of the classification challenge ahead\n",
    "\n",
    "The output will show a grid of randomly selected images with their category labels, giving us a qualitative view of what the model will need to learn to distinguish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e82cc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize sample images from different categories\n",
    "n_categories_to_show = 8\n",
    "n_images_per_category = 3\n",
    "\n",
    "# Select random categories\n",
    "random_categories = np.random.choice(df['category'].unique(), \n",
    "                                     size=min(n_categories_to_show, df['category'].nunique()), \n",
    "                                     replace=False)\n",
    "\n",
    "# Create figure\n",
    "fig, axes = plt.subplots(n_categories_to_show, n_images_per_category, \n",
    "                         figsize=(15, 2.5*n_categories_to_show))\n",
    "\n",
    "if n_categories_to_show == 1:\n",
    "    axes = axes.reshape(1, -1)\n",
    "\n",
    "print(\"Displaying sample images from random categories...\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "for i, category in enumerate(random_categories):\n",
    "    # Get images from this category\n",
    "    category_df = df[df['category'] == category]\n",
    "    \n",
    "    # Sample random images\n",
    "    sampled_images = category_df.sample(n=min(n_images_per_category, len(category_df)))\n",
    "    \n",
    "    for j, (idx, row) in enumerate(sampled_images.iterrows()):\n",
    "        img_path = row['image_path']\n",
    "        \n",
    "        try:\n",
    "            img = Image.open(img_path)\n",
    "            \n",
    "            # Display image\n",
    "            if n_categories_to_show > 1:\n",
    "                ax = axes[i, j]\n",
    "            else:\n",
    "                ax = axes[j]\n",
    "                \n",
    "            ax.imshow(img)\n",
    "            ax.axis('off')\n",
    "            \n",
    "            if j == 0:  # Add category label to first image in row\n",
    "                ax.set_title(f\"{category}\\n({len(category_df)} images)\", \n",
    "                           fontsize=10, fontweight='bold')\n",
    "            \n",
    "            img.close()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {img_path}: {e}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('images/sample_images_grid.png', dpi=150, bbox_inches='tight')\n",
    "print(\"✓ Sample grid saved to 'images/sample_images_grid.png'\")\n",
    "plt.show()\n",
    "\n",
    "# Additional: Show category name statistics\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Category Name Analysis:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Shortest category name: '{min(df['category'].unique(), key=len)}' ({len(min(df['category'].unique(), key=len))} chars)\")\n",
    "print(f\"Longest category name: '{max(df['category'].unique(), key=len)}' ({len(max(df['category'].unique(), key=len))} chars)\")\n",
    "print(f\"\\nAll categories ({len(df['category'].unique())} total):\")\n",
    "print(sorted(df['category'].unique()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
